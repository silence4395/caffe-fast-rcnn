I0909 17:15:13.940189  7315 caffe.cpp:312] Use GPU with device ID 0
I0909 17:15:13.962340  7315 caffe.cpp:316] GPU device name: Graphics Device
I0909 17:15:14.520406  7315 net.cpp:347] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0909 17:15:14.520675  7315 net.cpp:82] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "data/ilsvrc12/imagenet_mean.binaryproto"
  }
  data_param {
    source: "/mllib/imagenet/ilsvrc12/lmdb_resize/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRNRistretto"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
  quantization_param {
    bw_layer_in: 8
    bw_layer_out: 8
    fl_layer_in: -5
    fl_layer_out: -1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRNRistretto"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
  quantization_param {
    bw_layer_in: 8
    bw_layer_out: 8
    fl_layer_in: -3
    fl_layer_out: -1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0909 17:15:14.520898  7315 layer_factory.hpp:77] Creating layer data
I0909 17:15:14.521031  7315 db_lmdb.cpp:35] Opened lmdb /mllib/imagenet/ilsvrc12/lmdb_resize/ilsvrc12_val_lmdb
I0909 17:15:14.521072  7315 net.cpp:115] Creating Layer data
I0909 17:15:14.521090  7315 net.cpp:490] data -> data
I0909 17:15:14.521126  7315 net.cpp:490] data -> label
I0909 17:15:14.521152  7315 data_transformer.cpp:25] Loading mean file from: data/ilsvrc12/imagenet_mean.binaryproto
I0909 17:15:14.553236  7315 data_layer.cpp:45] output data size: 50,3,227,227
I0909 17:15:14.683037  7315 net.cpp:153] Setting up data
I0909 17:15:14.683245  7315 net.cpp:160] Top shape: 50 3 227 227 (7729350)
I0909 17:15:14.683293  7315 net.cpp:160] Top shape: 50 (50)
I0909 17:15:14.683336  7315 net.cpp:168] Memory required for data: 30917600
I0909 17:15:14.683398  7315 layer_factory.hpp:77] Creating layer label_data_1_split
I0909 17:15:14.683511  7315 net.cpp:115] Creating Layer label_data_1_split
I0909 17:15:14.683617  7315 net.cpp:516] label_data_1_split <- label
I0909 17:15:14.683688  7315 net.cpp:490] label_data_1_split -> label_data_1_split_0
I0909 17:15:14.683748  7315 net.cpp:490] label_data_1_split -> label_data_1_split_1
I0909 17:15:14.683923  7315 net.cpp:153] Setting up label_data_1_split
I0909 17:15:14.683984  7315 net.cpp:160] Top shape: 50 (50)
I0909 17:15:14.684031  7315 net.cpp:160] Top shape: 50 (50)
I0909 17:15:14.684077  7315 net.cpp:168] Memory required for data: 30918000
I0909 17:15:14.684118  7315 layer_factory.hpp:77] Creating layer conv1
I0909 17:15:14.684195  7315 net.cpp:115] Creating Layer conv1
I0909 17:15:14.684237  7315 net.cpp:516] conv1 <- data
I0909 17:15:14.684281  7315 net.cpp:490] conv1 -> conv1
I0909 17:15:14.697163  7315 net.cpp:153] Setting up conv1
I0909 17:15:14.697427  7315 net.cpp:160] Top shape: 50 96 55 55 (14520000)
I0909 17:15:14.697569  7315 net.cpp:168] Memory required for data: 88998000
I0909 17:15:14.697753  7315 layer_factory.hpp:77] Creating layer relu1
I0909 17:15:14.697815  7315 net.cpp:115] Creating Layer relu1
I0909 17:15:14.697865  7315 net.cpp:516] relu1 <- conv1
I0909 17:15:14.697919  7315 net.cpp:477] relu1 -> conv1 (in-place)
I0909 17:15:14.697958  7315 net.cpp:153] Setting up relu1
I0909 17:15:14.697973  7315 net.cpp:160] Top shape: 50 96 55 55 (14520000)
I0909 17:15:14.697983  7315 net.cpp:168] Memory required for data: 147078000
I0909 17:15:14.697993  7315 layer_factory.hpp:77] Creating layer pool1
I0909 17:15:14.698017  7315 net.cpp:115] Creating Layer pool1
I0909 17:15:14.698029  7315 net.cpp:516] pool1 <- conv1
I0909 17:15:14.698041  7315 net.cpp:490] pool1 -> pool1
I0909 17:15:14.698243  7315 net.cpp:153] Setting up pool1
I0909 17:15:14.698264  7315 net.cpp:160] Top shape: 50 96 27 27 (3499200)
I0909 17:15:14.698272  7315 net.cpp:168] Memory required for data: 161074800
I0909 17:15:14.698279  7315 layer_factory.hpp:77] Creating layer norm1
I0909 17:15:14.698385  7315 net.cpp:115] Creating Layer norm1
I0909 17:15:14.698503  7315 net.cpp:516] norm1 <- pool1
I0909 17:15:14.698546  7315 net.cpp:490] norm1 -> norm1
I0909 17:15:14.698644  7315 net.cpp:153] Setting up norm1
I0909 17:15:14.698683  7315 net.cpp:160] Top shape: 50 96 27 27 (3499200)
I0909 17:15:14.698705  7315 net.cpp:168] Memory required for data: 175071600
I0909 17:15:14.698722  7315 layer_factory.hpp:77] Creating layer conv2
I0909 17:15:14.698760  7315 net.cpp:115] Creating Layer conv2
I0909 17:15:14.698778  7315 net.cpp:516] conv2 <- norm1
I0909 17:15:14.698802  7315 net.cpp:490] conv2 -> conv2
I0909 17:15:14.715292  7315 net.cpp:153] Setting up conv2
I0909 17:15:14.715397  7315 net.cpp:160] Top shape: 50 256 27 27 (9331200)
I0909 17:15:14.715420  7315 net.cpp:168] Memory required for data: 212396400
I0909 17:15:14.715459  7315 layer_factory.hpp:77] Creating layer relu2
I0909 17:15:14.715492  7315 net.cpp:115] Creating Layer relu2
I0909 17:15:14.715577  7315 net.cpp:516] relu2 <- conv2
I0909 17:15:14.715657  7315 net.cpp:477] relu2 -> conv2 (in-place)
I0909 17:15:14.715759  7315 net.cpp:153] Setting up relu2
I0909 17:15:14.715816  7315 net.cpp:160] Top shape: 50 256 27 27 (9331200)
I0909 17:15:14.715893  7315 net.cpp:168] Memory required for data: 249721200
I0909 17:15:14.715934  7315 layer_factory.hpp:77] Creating layer pool2
I0909 17:15:14.715981  7315 net.cpp:115] Creating Layer pool2
I0909 17:15:14.716001  7315 net.cpp:516] pool2 <- conv2
I0909 17:15:14.716015  7315 net.cpp:490] pool2 -> pool2
I0909 17:15:14.716150  7315 net.cpp:153] Setting up pool2
I0909 17:15:14.716195  7315 net.cpp:160] Top shape: 50 256 13 13 (2163200)
I0909 17:15:14.716209  7315 net.cpp:168] Memory required for data: 258374000
I0909 17:15:14.716219  7315 layer_factory.hpp:77] Creating layer norm2
I0909 17:15:14.716243  7315 net.cpp:115] Creating Layer norm2
I0909 17:15:14.716259  7315 net.cpp:516] norm2 <- pool2
I0909 17:15:14.716274  7315 net.cpp:490] norm2 -> norm2
I0909 17:15:14.716361  7315 net.cpp:153] Setting up norm2
I0909 17:15:14.716395  7315 net.cpp:160] Top shape: 50 256 13 13 (2163200)
I0909 17:15:14.716406  7315 net.cpp:168] Memory required for data: 267026800
I0909 17:15:14.716418  7315 layer_factory.hpp:77] Creating layer conv3
I0909 17:15:14.716444  7315 net.cpp:115] Creating Layer conv3
I0909 17:15:14.716457  7315 net.cpp:516] conv3 <- norm2
I0909 17:15:14.716480  7315 net.cpp:490] conv3 -> conv3
I0909 17:15:14.758877  7315 net.cpp:153] Setting up conv3
I0909 17:15:14.759102  7315 net.cpp:160] Top shape: 50 384 13 13 (3244800)
I0909 17:15:14.759162  7315 net.cpp:168] Memory required for data: 280006000
I0909 17:15:14.759248  7315 layer_factory.hpp:77] Creating layer relu3
I0909 17:15:14.759305  7315 net.cpp:115] Creating Layer relu3
I0909 17:15:14.759347  7315 net.cpp:516] relu3 <- conv3
I0909 17:15:14.759397  7315 net.cpp:477] relu3 -> conv3 (in-place)
I0909 17:15:14.759451  7315 net.cpp:153] Setting up relu3
I0909 17:15:14.759506  7315 net.cpp:160] Top shape: 50 384 13 13 (3244800)
I0909 17:15:14.759567  7315 net.cpp:168] Memory required for data: 292985200
I0909 17:15:14.759620  7315 layer_factory.hpp:77] Creating layer conv4
I0909 17:15:14.759701  7315 net.cpp:115] Creating Layer conv4
I0909 17:15:14.759771  7315 net.cpp:516] conv4 <- conv3
I0909 17:15:14.759853  7315 net.cpp:490] conv4 -> conv4
I0909 17:15:14.793344  7315 net.cpp:153] Setting up conv4
I0909 17:15:14.793553  7315 net.cpp:160] Top shape: 50 384 13 13 (3244800)
I0909 17:15:14.793606  7315 net.cpp:168] Memory required for data: 305964400
I0909 17:15:14.793655  7315 layer_factory.hpp:77] Creating layer relu4
I0909 17:15:14.793709  7315 net.cpp:115] Creating Layer relu4
I0909 17:15:14.793824  7315 net.cpp:516] relu4 <- conv4
I0909 17:15:14.794023  7315 net.cpp:477] relu4 -> conv4 (in-place)
I0909 17:15:14.794116  7315 net.cpp:153] Setting up relu4
I0909 17:15:14.794188  7315 net.cpp:160] Top shape: 50 384 13 13 (3244800)
I0909 17:15:14.794255  7315 net.cpp:168] Memory required for data: 318943600
I0909 17:15:14.794323  7315 layer_factory.hpp:77] Creating layer conv5
I0909 17:15:14.794445  7315 net.cpp:115] Creating Layer conv5
I0909 17:15:14.794509  7315 net.cpp:516] conv5 <- conv4
I0909 17:15:14.794559  7315 net.cpp:490] conv5 -> conv5
I0909 17:15:14.810956  7315 net.cpp:153] Setting up conv5
I0909 17:15:14.811044  7315 net.cpp:160] Top shape: 50 256 13 13 (2163200)
I0909 17:15:14.811055  7315 net.cpp:168] Memory required for data: 327596400
I0909 17:15:14.811085  7315 layer_factory.hpp:77] Creating layer relu5
I0909 17:15:14.811110  7315 net.cpp:115] Creating Layer relu5
I0909 17:15:14.811158  7315 net.cpp:516] relu5 <- conv5
I0909 17:15:14.811179  7315 net.cpp:477] relu5 -> conv5 (in-place)
I0909 17:15:14.811233  7315 net.cpp:153] Setting up relu5
I0909 17:15:14.811249  7315 net.cpp:160] Top shape: 50 256 13 13 (2163200)
I0909 17:15:14.811259  7315 net.cpp:168] Memory required for data: 336249200
I0909 17:15:14.811269  7315 layer_factory.hpp:77] Creating layer pool5
I0909 17:15:14.811312  7315 net.cpp:115] Creating Layer pool5
I0909 17:15:14.811331  7315 net.cpp:516] pool5 <- conv5
I0909 17:15:14.811358  7315 net.cpp:490] pool5 -> pool5
I0909 17:15:14.811458  7315 net.cpp:153] Setting up pool5
I0909 17:15:14.811476  7315 net.cpp:160] Top shape: 50 256 6 6 (460800)
I0909 17:15:14.811486  7315 net.cpp:168] Memory required for data: 338092400
I0909 17:15:14.811522  7315 layer_factory.hpp:77] Creating layer fc6
I0909 17:15:14.811556  7315 net.cpp:115] Creating Layer fc6
I0909 17:15:14.811569  7315 net.cpp:516] fc6 <- pool5
I0909 17:15:14.811585  7315 net.cpp:490] fc6 -> fc6
I0909 17:15:16.188041  7315 net.cpp:153] Setting up fc6
I0909 17:15:16.188159  7315 net.cpp:160] Top shape: 50 4096 (204800)
I0909 17:15:16.188184  7315 net.cpp:168] Memory required for data: 338911600
I0909 17:15:16.188225  7315 layer_factory.hpp:77] Creating layer relu6
I0909 17:15:16.188264  7315 net.cpp:115] Creating Layer relu6
I0909 17:15:16.188299  7315 net.cpp:516] relu6 <- fc6
I0909 17:15:16.188330  7315 net.cpp:477] relu6 -> fc6 (in-place)
I0909 17:15:16.188380  7315 net.cpp:153] Setting up relu6
I0909 17:15:16.188395  7315 net.cpp:160] Top shape: 50 4096 (204800)
I0909 17:15:16.188402  7315 net.cpp:168] Memory required for data: 339730800
I0909 17:15:16.188410  7315 layer_factory.hpp:77] Creating layer drop6
I0909 17:15:16.188446  7315 net.cpp:115] Creating Layer drop6
I0909 17:15:16.188459  7315 net.cpp:516] drop6 <- fc6
I0909 17:15:16.188472  7315 net.cpp:477] drop6 -> fc6 (in-place)
I0909 17:15:16.188540  7315 net.cpp:153] Setting up drop6
I0909 17:15:16.188565  7315 net.cpp:160] Top shape: 50 4096 (204800)
I0909 17:15:16.188572  7315 net.cpp:168] Memory required for data: 340550000
I0909 17:15:16.188580  7315 layer_factory.hpp:77] Creating layer fc7
I0909 17:15:16.188601  7315 net.cpp:115] Creating Layer fc7
I0909 17:15:16.188608  7315 net.cpp:516] fc7 <- fc6
I0909 17:15:16.188622  7315 net.cpp:490] fc7 -> fc7
I0909 17:15:16.740959  7315 net.cpp:153] Setting up fc7
I0909 17:15:16.741008  7315 net.cpp:160] Top shape: 50 4096 (204800)
I0909 17:15:16.741014  7315 net.cpp:168] Memory required for data: 341369200
I0909 17:15:16.741027  7315 layer_factory.hpp:77] Creating layer relu7
I0909 17:15:16.741042  7315 net.cpp:115] Creating Layer relu7
I0909 17:15:16.741053  7315 net.cpp:516] relu7 <- fc7
I0909 17:15:16.741063  7315 net.cpp:477] relu7 -> fc7 (in-place)
I0909 17:15:16.741076  7315 net.cpp:153] Setting up relu7
I0909 17:15:16.741083  7315 net.cpp:160] Top shape: 50 4096 (204800)
I0909 17:15:16.741088  7315 net.cpp:168] Memory required for data: 342188400
I0909 17:15:16.741092  7315 layer_factory.hpp:77] Creating layer drop7
I0909 17:15:16.741103  7315 net.cpp:115] Creating Layer drop7
I0909 17:15:16.741109  7315 net.cpp:516] drop7 <- fc7
I0909 17:15:16.741116  7315 net.cpp:477] drop7 -> fc7 (in-place)
I0909 17:15:16.741173  7315 net.cpp:153] Setting up drop7
I0909 17:15:16.741184  7315 net.cpp:160] Top shape: 50 4096 (204800)
I0909 17:15:16.741190  7315 net.cpp:168] Memory required for data: 343007600
I0909 17:15:16.741195  7315 layer_factory.hpp:77] Creating layer fc8
I0909 17:15:16.741207  7315 net.cpp:115] Creating Layer fc8
I0909 17:15:16.741212  7315 net.cpp:516] fc8 <- fc7
I0909 17:15:16.741220  7315 net.cpp:490] fc8 -> fc8
I0909 17:15:16.889267  7315 net.cpp:153] Setting up fc8
I0909 17:15:16.889336  7315 net.cpp:160] Top shape: 50 1000 (50000)
I0909 17:15:16.889343  7315 net.cpp:168] Memory required for data: 343207600
I0909 17:15:16.889358  7315 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0909 17:15:16.889371  7315 net.cpp:115] Creating Layer fc8_fc8_0_split
I0909 17:15:16.889408  7315 net.cpp:516] fc8_fc8_0_split <- fc8
I0909 17:15:16.889420  7315 net.cpp:490] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0909 17:15:16.889433  7315 net.cpp:490] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0909 17:15:16.889526  7315 net.cpp:153] Setting up fc8_fc8_0_split
I0909 17:15:16.889550  7315 net.cpp:160] Top shape: 50 1000 (50000)
I0909 17:15:16.889556  7315 net.cpp:160] Top shape: 50 1000 (50000)
I0909 17:15:16.889561  7315 net.cpp:168] Memory required for data: 343607600
I0909 17:15:16.889567  7315 layer_factory.hpp:77] Creating layer accuracy
I0909 17:15:16.889586  7315 net.cpp:115] Creating Layer accuracy
I0909 17:15:16.889595  7315 net.cpp:516] accuracy <- fc8_fc8_0_split_0
I0909 17:15:16.889601  7315 net.cpp:516] accuracy <- label_data_1_split_0
I0909 17:15:16.889609  7315 net.cpp:490] accuracy -> accuracy
I0909 17:15:16.889653  7315 net.cpp:153] Setting up accuracy
I0909 17:15:16.889662  7315 net.cpp:160] Top shape: (1)
I0909 17:15:16.889667  7315 net.cpp:168] Memory required for data: 343607604
I0909 17:15:16.889672  7315 layer_factory.hpp:77] Creating layer loss
I0909 17:15:16.889684  7315 net.cpp:115] Creating Layer loss
I0909 17:15:16.889691  7315 net.cpp:516] loss <- fc8_fc8_0_split_1
I0909 17:15:16.889698  7315 net.cpp:516] loss <- label_data_1_split_1
I0909 17:15:16.889705  7315 net.cpp:490] loss -> loss
I0909 17:15:16.889725  7315 layer_factory.hpp:77] Creating layer loss
I0909 17:15:16.889900  7315 net.cpp:153] Setting up loss
I0909 17:15:16.889915  7315 net.cpp:160] Top shape: (1)
I0909 17:15:16.889921  7315 net.cpp:163]     with loss weight 1
I0909 17:15:16.889953  7315 net.cpp:168] Memory required for data: 343607608
I0909 17:15:16.889961  7315 net.cpp:203]  [ UPDATE INFO ]conv1 needs update itself weights.
I0909 17:15:16.889966  7315 net.cpp:205]  [ UPDATE INFO ]conv1 needs update itself bias.
I0909 17:15:16.889969  7315 net.cpp:203]  [ UPDATE INFO ]conv2 needs update itself weights.
I0909 17:15:16.889974  7315 net.cpp:205]  [ UPDATE INFO ]conv2 needs update itself bias.
I0909 17:15:16.889979  7315 net.cpp:203]  [ UPDATE INFO ]conv3 needs update itself weights.
I0909 17:15:16.889986  7315 net.cpp:205]  [ UPDATE INFO ]conv3 needs update itself bias.
I0909 17:15:16.889991  7315 net.cpp:203]  [ UPDATE INFO ]conv4 needs update itself weights.
I0909 17:15:16.889995  7315 net.cpp:205]  [ UPDATE INFO ]conv4 needs update itself bias.
I0909 17:15:16.890000  7315 net.cpp:203]  [ UPDATE INFO ]conv5 needs update itself weights.
I0909 17:15:16.890005  7315 net.cpp:205]  [ UPDATE INFO ]conv5 needs update itself bias.
I0909 17:15:16.890009  7315 net.cpp:203]  [ UPDATE INFO ]fc6 needs update itself weights.
I0909 17:15:16.890014  7315 net.cpp:205]  [ UPDATE INFO ]fc6 needs update itself bias.
I0909 17:15:16.890018  7315 net.cpp:203]  [ UPDATE INFO ]fc7 needs update itself weights.
I0909 17:15:16.890023  7315 net.cpp:205]  [ UPDATE INFO ]fc7 needs update itself bias.
I0909 17:15:16.890027  7315 net.cpp:203]  [ UPDATE INFO ]fc8 needs update itself weights.
I0909 17:15:16.890031  7315 net.cpp:205]  [ UPDATE INFO ]fc8 needs update itself bias.
I0909 17:15:16.890036  7315 net.cpp:251]  [ DIFF BP INFO] loss needs backward computation.
I0909 17:15:16.890044  7315 net.cpp:253]  [ DIFF BP INFO] accuracy does not need backward computation.
I0909 17:15:16.890079  7315 net.cpp:251]  [ DIFF BP INFO] fc8_fc8_0_split needs backward computation.
I0909 17:15:16.890085  7315 net.cpp:251]  [ DIFF BP INFO] fc8 needs backward computation.
I0909 17:15:16.890091  7315 net.cpp:251]  [ DIFF BP INFO] drop7 needs backward computation.
I0909 17:15:16.890096  7315 net.cpp:251]  [ DIFF BP INFO] relu7 needs backward computation.
I0909 17:15:16.890102  7315 net.cpp:251]  [ DIFF BP INFO] fc7 needs backward computation.
I0909 17:15:16.890112  7315 net.cpp:251]  [ DIFF BP INFO] drop6 needs backward computation.
I0909 17:15:16.890118  7315 net.cpp:251]  [ DIFF BP INFO] relu6 needs backward computation.
I0909 17:15:16.890123  7315 net.cpp:251]  [ DIFF BP INFO] fc6 needs backward computation.
I0909 17:15:16.890128  7315 net.cpp:251]  [ DIFF BP INFO] pool5 needs backward computation.
I0909 17:15:16.890135  7315 net.cpp:251]  [ DIFF BP INFO] relu5 needs backward computation.
I0909 17:15:16.890139  7315 net.cpp:251]  [ DIFF BP INFO] conv5 needs backward computation.
I0909 17:15:16.890144  7315 net.cpp:251]  [ DIFF BP INFO] relu4 needs backward computation.
I0909 17:15:16.890149  7315 net.cpp:251]  [ DIFF BP INFO] conv4 needs backward computation.
I0909 17:15:16.890156  7315 net.cpp:251]  [ DIFF BP INFO] relu3 needs backward computation.
I0909 17:15:16.890161  7315 net.cpp:251]  [ DIFF BP INFO] conv3 needs backward computation.
I0909 17:15:16.890166  7315 net.cpp:251]  [ DIFF BP INFO] norm2 needs backward computation.
I0909 17:15:16.890172  7315 net.cpp:251]  [ DIFF BP INFO] pool2 needs backward computation.
I0909 17:15:16.890177  7315 net.cpp:251]  [ DIFF BP INFO] relu2 needs backward computation.
I0909 17:15:16.890182  7315 net.cpp:251]  [ DIFF BP INFO] conv2 needs backward computation.
I0909 17:15:16.890187  7315 net.cpp:251]  [ DIFF BP INFO] norm1 needs backward computation.
I0909 17:15:16.890193  7315 net.cpp:251]  [ DIFF BP INFO] pool1 needs backward computation.
I0909 17:15:16.890198  7315 net.cpp:251]  [ DIFF BP INFO] relu1 needs backward computation.
I0909 17:15:16.890203  7315 net.cpp:251]  [ DIFF BP INFO] conv1 needs backward computation.
I0909 17:15:16.890209  7315 net.cpp:253]  [ DIFF BP INFO] label_data_1_split does not need backward computation.
I0909 17:15:16.890215  7315 net.cpp:253]  [ DIFF BP INFO] data does not need backward computation.
I0909 17:15:16.890220  7315 net.cpp:295] This network produces output accuracy
I0909 17:15:16.890225  7315 net.cpp:295] This network produces output loss
I0909 17:15:16.890244  7315 net.cpp:308] Network initialization done.
I0909 17:15:19.577184  7315 upgrade_proto.cpp:44] Attempting to upgrade input file specified using deprecated transformation parameters: models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0909 17:15:19.577299  7315 upgrade_proto.cpp:47] Successfully upgraded file specified using deprecated data transformation parameters.
W0909 17:15:19.577329  7315 upgrade_proto.cpp:49] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0909 17:15:19.577774  7315 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0909 17:17:24.389263  7315 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter
I0909 17:17:24.551641  7315 caffe.cpp:327] Running for 50 iterations.
I0909 17:17:24.662534  7315 caffe.cpp:350] Batch 0, accuracy = 0.46
I0909 17:17:24.662575  7315 caffe.cpp:350] Batch 0, loss = 2.15492
I0909 17:17:24.720305  7315 caffe.cpp:350] Batch 1, accuracy = 0.64
I0909 17:17:24.720347  7315 caffe.cpp:350] Batch 1, loss = 1.56407
I0909 17:17:24.777823  7315 caffe.cpp:350] Batch 2, accuracy = 0.6
I0909 17:17:24.777846  7315 caffe.cpp:350] Batch 2, loss = 1.28737
I0909 17:17:24.836026  7315 caffe.cpp:350] Batch 3, accuracy = 0.48
I0909 17:17:24.836635  7315 caffe.cpp:350] Batch 3, loss = 2.29563
I0909 17:17:24.903046  7315 caffe.cpp:350] Batch 4, accuracy = 0.58
I0909 17:17:24.903116  7315 caffe.cpp:350] Batch 4, loss = 2.55491
I0909 17:17:24.961602  7315 caffe.cpp:350] Batch 5, accuracy = 0.52
I0909 17:17:24.961843  7315 caffe.cpp:350] Batch 5, loss = 1.47063
I0909 17:17:25.019400  7315 caffe.cpp:350] Batch 6, accuracy = 0.5
I0909 17:17:25.019585  7315 caffe.cpp:350] Batch 6, loss = 2.19374
I0909 17:17:25.077019  7315 caffe.cpp:350] Batch 7, accuracy = 0.54
I0909 17:17:25.077114  7315 caffe.cpp:350] Batch 7, loss = 1.84206
I0909 17:17:25.134171  7315 caffe.cpp:350] Batch 8, accuracy = 0.6
I0909 17:17:25.134475  7315 caffe.cpp:350] Batch 8, loss = 1.59169
I0909 17:17:25.193037  7315 caffe.cpp:350] Batch 9, accuracy = 0.56
I0909 17:17:25.193351  7315 caffe.cpp:350] Batch 9, loss = 1.926
I0909 17:17:25.243054  7315 caffe.cpp:350] Batch 10, accuracy = 0.58
I0909 17:17:25.243293  7315 caffe.cpp:350] Batch 10, loss = 1.96813
I0909 17:17:25.300659  7315 caffe.cpp:350] Batch 11, accuracy = 0.56
I0909 17:17:25.300889  7315 caffe.cpp:350] Batch 11, loss = 2.11605
I0909 17:17:25.360146  7315 caffe.cpp:350] Batch 12, accuracy = 0.56
I0909 17:17:25.360412  7315 caffe.cpp:350] Batch 12, loss = 2.0217
I0909 17:17:25.416810  7315 caffe.cpp:350] Batch 13, accuracy = 0.62
I0909 17:17:25.417038  7315 caffe.cpp:350] Batch 13, loss = 1.70636
I0909 17:17:25.466248  7315 caffe.cpp:350] Batch 14, accuracy = 0.64
I0909 17:17:25.466434  7315 caffe.cpp:350] Batch 14, loss = 1.44694
I0909 17:17:25.466516  7315 blocking_queue.cpp:50] Waiting for data
I0909 17:17:25.538974  7315 caffe.cpp:350] Batch 15, accuracy = 0.74
I0909 17:17:25.539137  7315 caffe.cpp:350] Batch 15, loss = 1.55171
I0909 17:17:25.620775  7315 caffe.cpp:350] Batch 16, accuracy = 0.56
I0909 17:17:25.621043  7315 caffe.cpp:350] Batch 16, loss = 2.09217
I0909 17:17:25.700670  7315 caffe.cpp:350] Batch 17, accuracy = 0.44
I0909 17:17:25.700757  7315 caffe.cpp:350] Batch 17, loss = 2.1887
I0909 17:17:25.776134  7315 caffe.cpp:350] Batch 18, accuracy = 0.44
I0909 17:17:25.776295  7315 caffe.cpp:350] Batch 18, loss = 1.83336
I0909 17:17:25.865347  7315 caffe.cpp:350] Batch 19, accuracy = 0.44
I0909 17:17:25.865514  7315 caffe.cpp:350] Batch 19, loss = 2.2615
I0909 17:17:25.923688  7315 caffe.cpp:350] Batch 20, accuracy = 0.54
I0909 17:17:25.923905  7315 caffe.cpp:350] Batch 20, loss = 1.66687
I0909 17:17:25.980214  7315 caffe.cpp:350] Batch 21, accuracy = 0.5
I0909 17:17:25.980360  7315 caffe.cpp:350] Batch 21, loss = 2.00863
I0909 17:17:26.033270  7315 caffe.cpp:350] Batch 22, accuracy = 0.5
I0909 17:17:26.033334  7315 caffe.cpp:350] Batch 22, loss = 1.78138
I0909 17:17:26.093899  7315 caffe.cpp:350] Batch 23, accuracy = 0.7
I0909 17:17:26.093946  7315 caffe.cpp:350] Batch 23, loss = 0.963688
I0909 17:17:26.152659  7315 caffe.cpp:350] Batch 24, accuracy = 0.58
I0909 17:17:26.152705  7315 caffe.cpp:350] Batch 24, loss = 1.43273
I0909 17:17:26.206076  7315 caffe.cpp:350] Batch 25, accuracy = 0.62
I0909 17:17:26.206121  7315 caffe.cpp:350] Batch 25, loss = 1.68801
I0909 17:17:26.259107  7315 caffe.cpp:350] Batch 26, accuracy = 0.64
I0909 17:17:26.259155  7315 caffe.cpp:350] Batch 26, loss = 2.0726
I0909 17:17:26.311986  7315 caffe.cpp:350] Batch 27, accuracy = 0.62
I0909 17:17:26.312038  7315 caffe.cpp:350] Batch 27, loss = 1.70267
I0909 17:17:26.364981  7315 caffe.cpp:350] Batch 28, accuracy = 0.48
I0909 17:17:26.365031  7315 caffe.cpp:350] Batch 28, loss = 1.99203
I0909 17:17:26.417953  7315 caffe.cpp:350] Batch 29, accuracy = 0.6
I0909 17:17:26.418048  7315 caffe.cpp:350] Batch 29, loss = 2.05654
I0909 17:17:26.470950  7315 caffe.cpp:350] Batch 30, accuracy = 0.62
I0909 17:17:26.471004  7315 caffe.cpp:350] Batch 30, loss = 1.4898
I0909 17:17:26.523957  7315 caffe.cpp:350] Batch 31, accuracy = 0.5
I0909 17:17:26.524008  7315 caffe.cpp:350] Batch 31, loss = 1.99575
I0909 17:17:26.583510  7315 caffe.cpp:350] Batch 32, accuracy = 0.44
I0909 17:17:26.583796  7315 caffe.cpp:350] Batch 32, loss = 2.73058
I0909 17:17:26.634169  7315 caffe.cpp:350] Batch 33, accuracy = 0.64
I0909 17:17:26.634459  7315 caffe.cpp:350] Batch 33, loss = 1.53709
I0909 17:17:26.691100  7315 caffe.cpp:350] Batch 34, accuracy = 0.62
I0909 17:17:26.691262  7315 caffe.cpp:350] Batch 34, loss = 1.69098
I0909 17:17:26.783987  7315 caffe.cpp:350] Batch 35, accuracy = 0.64
I0909 17:17:26.784235  7315 caffe.cpp:350] Batch 35, loss = 1.62052
I0909 17:17:26.864064  7315 caffe.cpp:350] Batch 36, accuracy = 0.64
I0909 17:17:26.864110  7315 caffe.cpp:350] Batch 36, loss = 1.74655
I0909 17:17:26.917109  7315 caffe.cpp:350] Batch 37, accuracy = 0.58
I0909 17:17:26.917152  7315 caffe.cpp:350] Batch 37, loss = 1.48062
I0909 17:17:26.970340  7315 caffe.cpp:350] Batch 38, accuracy = 0.56
I0909 17:17:26.970386  7315 caffe.cpp:350] Batch 38, loss = 1.74902
I0909 17:17:27.029798  7315 caffe.cpp:350] Batch 39, accuracy = 0.48
I0909 17:17:27.029978  7315 caffe.cpp:350] Batch 39, loss = 2.42153
I0909 17:17:27.084978  7315 caffe.cpp:350] Batch 40, accuracy = 0.56
I0909 17:17:27.085039  7315 caffe.cpp:350] Batch 40, loss = 1.88137
I0909 17:17:27.142952  7315 caffe.cpp:350] Batch 41, accuracy = 0.54
I0909 17:17:27.143173  7315 caffe.cpp:350] Batch 41, loss = 1.84438
I0909 17:17:27.203280  7315 caffe.cpp:350] Batch 42, accuracy = 0.56
I0909 17:17:27.203521  7315 caffe.cpp:350] Batch 42, loss = 1.59354
I0909 17:17:27.256834  7315 caffe.cpp:350] Batch 43, accuracy = 0.6
I0909 17:17:27.257199  7315 caffe.cpp:350] Batch 43, loss = 1.75817
I0909 17:17:27.315413  7315 caffe.cpp:350] Batch 44, accuracy = 0.6
I0909 17:17:27.315579  7315 caffe.cpp:350] Batch 44, loss = 1.44569
I0909 17:17:27.384299  7315 caffe.cpp:350] Batch 45, accuracy = 0.46
I0909 17:17:27.384454  7315 caffe.cpp:350] Batch 45, loss = 1.97404
I0909 17:17:27.461555  7315 caffe.cpp:350] Batch 46, accuracy = 0.66
I0909 17:17:27.461756  7315 caffe.cpp:350] Batch 46, loss = 1.36666
I0909 17:17:27.541179  7315 caffe.cpp:350] Batch 47, accuracy = 0.52
I0909 17:17:27.541239  7315 caffe.cpp:350] Batch 47, loss = 1.93827
I0909 17:17:27.633342  7315 caffe.cpp:350] Batch 48, accuracy = 0.58
I0909 17:17:27.633520  7315 caffe.cpp:350] Batch 48, loss = 1.59823
I0909 17:17:27.720688  7315 caffe.cpp:350] Batch 49, accuracy = 0.56
I0909 17:17:27.720952  7315 caffe.cpp:350] Batch 49, loss = 1.37279
I0909 17:17:27.721030  7315 caffe.cpp:355] Loss: 1.81337
I0909 17:17:27.721135  7315 caffe.cpp:367] accuracy = 0.564
I0909 17:17:27.721257  7315 caffe.cpp:367] loss = 1.81337 (* 1 = 1.81337 loss)
