# configure file for pruning, by zhluo 3/28/2017
# usage:
#     eg. ./examples/mnist/train_lenet.sh --flagfile=models/prun_cfg.cfg

# google gflags signal implication:
#     prun_conv: only prun CONV layers
#     prun_fc: only prun FC layers
#     prun_fc_num: the number of the FC layers
#     prun_retrain: retrain after pruning
#     sparse_csc: blob use csc sparse storage pattern
#     sparse_col: treat weight value as N * sparse_col array
#     idx_diff_xxx: max diff distance
#     quan_enable: enable quantization
#     quan_k_min/max: k-means K min/max value
#     quan_max_iter: k-means max iteration

# local pruning strategy
# eg. prun CONV layers and FC layers:
#     prun_conv on => prun_retrain on => prun_retrain off, prun_fc on => prun_conv off, prun_retrain on

# NOTE: pruning
#     1. declare follow signals in include/caffe/prun_cfg.hpp
#     2. define follow signals in the follow file:
#            tools/upgrade_net_proto_binary.cpp
#            tools/upgrade_solver_proto_text.cpp
#            tools/caffe.cpp
#            tools/extract_features.cpp
#            tools/upgrade_net_proto_text.cpp
#            tools/convert_imageset.cpp
#            tools/compute_image_mean.cpp
#            examples/mnist/convert_mnist_data.cpp
#            examples/siamese/convert_mnist_siamese_data.cpp
#            examples/cifar10/convert_cifar_data.cpp
#            examples/cpp_classification/classification.cpp
#        eg. DEFINE_name(name, default value, "explain");

# NOTE: sparse
#
#  1.only sparse CONV layers: set "prun_conv" and "sparse_csc";
#  2.only sparse FC layers: set "prun_fc" and "sparse_csc";
#  3.sparse all layers:
#     prun_conv on, sparse_csc on =>  prun_conv off => OK!
#

# NOTE: quantization
#     1.when pruning, the "sparse_csc" or "quan_enable" maybe valid.
#     2.update quantization: turn on "prun_retrain" and "quan_enable"

# NOTE:
# fc ratio: < lenet > fc1:0.92 fc2: 0.81
# conv ratio: < lenet > conv1:0.34 conv2:0.88


# conv
--prun_conv=0
--conv_ratio_0=0.34
--conv_ratio_1=0.88
--conv_ratio_2=0
# fc
--prun_fc=0
--fc_ratio_0=0.92
--fc_ratio_1=0.81
--fc_ratio_2=0
--prun_fc_num=2
# retrain
--prun_retrain=0
# csc
--sparse_csc=1
--sparse_col=1
--idx_diff_conv=8
--idx_diff_fc=5
# quantization
# quan_k_max: 2^k
--quan_enable=1
--quan_k_min=4
--quan_k_max=8
--quan_max_iter=10000
--quan_retrain=0
